{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"First, lets do some feature engineering","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain_input = pd.read_csv('/kaggle/input/titanic/train.csv')\ntrain_input.head()\ntarget = train_input['Survived']\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ntrain_input = train_input.drop(['Name', 'Ticket', 'Fare', 'Cabin', 'PassengerId', 'Survived'], axis=1)\ntrain_input.head()\n\ntrain_input.isnull().sum()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-21T17:18:47.593068Z","iopub.execute_input":"2023-05-21T17:18:47.593554Z","iopub.status.idle":"2023-05-21T17:18:47.621014Z","shell.execute_reply.started":"2023-05-21T17:18:47.593517Z","shell.execute_reply":"2023-05-21T17:18:47.619519Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"Pclass        0\nSex           0\nAge         177\nSibSp         0\nParch         0\nEmbarked      2\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_input.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:18:50.607365Z","iopub.execute_input":"2023-05-21T17:18:50.607859Z","iopub.status.idle":"2023-05-21T17:18:50.618542Z","shell.execute_reply.started":"2023-05-21T17:18:50.607823Z","shell.execute_reply":"2023-05-21T17:18:50.616648Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(891, 6)"},"metadata":{}}]},{"cell_type":"markdown","source":"Changing categories to numerical values","metadata":{}},{"cell_type":"code","source":"def change_gender(x):\n    if x == 'male':\n        return 0\n    else:\n        return 1\n    \ndef change_embarked(x):\n    if x == 'S':\n        return 0\n    if x == 'C':\n        return 1\n    else:\n        return 2\n\n    \ntrain_input.Sex = train_input.Sex.apply(change_gender)\ntrain_input.Embarked = train_input.Embarked.apply(change_embarked)\n\ntrain_input.head()\ntrain_input.Age = train_input.Age.fillna(value=train_input.Age.mean())\ntrain_input.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:18:52.495294Z","iopub.execute_input":"2023-05-21T17:18:52.496549Z","iopub.status.idle":"2023-05-21T17:18:52.516980Z","shell.execute_reply.started":"2023-05-21T17:18:52.496500Z","shell.execute_reply":"2023-05-21T17:18:52.515653Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Pclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nEmbarked    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscale = StandardScaler()\ntrain_input = pd.DataFrame(scale.fit_transform(train_input))\n\ntrain_input.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:18:56.314584Z","iopub.execute_input":"2023-05-21T17:18:56.315031Z","iopub.status.idle":"2023-05-21T17:18:57.036624Z","shell.execute_reply.started":"2023-05-21T17:18:56.314999Z","shell.execute_reply":"2023-05-21T17:18:57.035393Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"          0         1         2         3         4         5\n0  0.827377 -0.737695 -0.592481  0.432793 -0.473674 -0.571870\n1 -1.566107  1.355574  0.638789  0.432793 -0.473674  0.991124\n2  0.827377  1.355574 -0.284663 -0.474545 -0.473674 -0.571870\n3 -1.566107  1.355574  0.407926  0.432793 -0.473674 -0.571870\n4  0.827377 -0.737695  0.407926 -0.474545 -0.473674 -0.571870","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.827377</td>\n      <td>-0.737695</td>\n      <td>-0.592481</td>\n      <td>0.432793</td>\n      <td>-0.473674</td>\n      <td>-0.571870</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.566107</td>\n      <td>1.355574</td>\n      <td>0.638789</td>\n      <td>0.432793</td>\n      <td>-0.473674</td>\n      <td>0.991124</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.827377</td>\n      <td>1.355574</td>\n      <td>-0.284663</td>\n      <td>-0.474545</td>\n      <td>-0.473674</td>\n      <td>-0.571870</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.566107</td>\n      <td>1.355574</td>\n      <td>0.407926</td>\n      <td>0.432793</td>\n      <td>-0.473674</td>\n      <td>-0.571870</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.827377</td>\n      <td>-0.737695</td>\n      <td>0.407926</td>\n      <td>-0.474545</td>\n      <td>-0.473674</td>\n      <td>-0.571870</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Defining the model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport keras \nfrom keras.layers import Dense, Dropout, Input\nfrom keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Dense(units = 4, input_shape = (6,), activation = 'relu'))\nmodel.add(Dense(units = 8, activation = 'relu'))\nmodel.add(Dense(units = 16, activation = 'relu'))\nmodel.add(Dense(units = 32, activation = 'relu'))\nmodel.add(Dense(units = 64, activation = 'relu'))\nmodel.add(Dense(units = 128, activation = 'relu'))\nmodel.add(Dense(units = 64, activation = 'relu'))\nmodel.add(Dense(units = 32, activation = 'relu'))\nmodel.add(Dense(units = 16, activation = 'relu'))\nmodel.add(Dense(units = 8, activation = 'relu'))\nmodel.add(Dense(units = 4, activation = 'relu'))\nmodel.add(Dense(units = 1 , activation = 'sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:19:02.408089Z","iopub.execute_input":"2023-05-21T17:19:02.408533Z","iopub.status.idle":"2023-05-21T17:19:11.866199Z","shell.execute_reply.started":"2023-05-21T17:19:02.408500Z","shell.execute_reply":"2023-05-21T17:19:11.864877Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Compiling the model","metadata":{}},{"cell_type":"code","source":"model.compile(loss = tf.keras.losses.binary_crossentropy, optimizer = tf.keras.optimizers.Adam(), metrics = ['acc'])\nmodel.fit(train_input, target, batch_size = 16, verbose = 2, epochs = 200)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T17:19:19.762538Z","iopub.execute_input":"2023-05-21T17:19:19.762949Z","iopub.status.idle":"2023-05-21T17:19:53.015646Z","shell.execute_reply.started":"2023-05-21T17:19:19.762917Z","shell.execute_reply":"2023-05-21T17:19:53.014182Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/200\n56/56 - 3s - loss: 0.6075 - acc: 0.7419 - 3s/epoch - 47ms/step\nEpoch 2/200\n56/56 - 0s - loss: 0.4738 - acc: 0.8092 - 152ms/epoch - 3ms/step\nEpoch 3/200\n56/56 - 0s - loss: 0.4679 - acc: 0.8047 - 148ms/epoch - 3ms/step\nEpoch 4/200\n56/56 - 0s - loss: 0.4668 - acc: 0.8058 - 143ms/epoch - 3ms/step\nEpoch 5/200\n56/56 - 0s - loss: 0.4510 - acc: 0.8227 - 157ms/epoch - 3ms/step\nEpoch 6/200\n56/56 - 0s - loss: 0.4548 - acc: 0.8182 - 155ms/epoch - 3ms/step\nEpoch 7/200\n56/56 - 0s - loss: 0.4479 - acc: 0.8148 - 154ms/epoch - 3ms/step\nEpoch 8/200\n56/56 - 0s - loss: 0.4379 - acc: 0.8215 - 150ms/epoch - 3ms/step\nEpoch 9/200\n56/56 - 0s - loss: 0.4433 - acc: 0.8148 - 151ms/epoch - 3ms/step\nEpoch 10/200\n56/56 - 0s - loss: 0.4341 - acc: 0.8260 - 146ms/epoch - 3ms/step\nEpoch 11/200\n56/56 - 0s - loss: 0.4264 - acc: 0.8238 - 145ms/epoch - 3ms/step\nEpoch 12/200\n56/56 - 0s - loss: 0.4236 - acc: 0.8215 - 150ms/epoch - 3ms/step\nEpoch 13/200\n56/56 - 0s - loss: 0.4231 - acc: 0.8316 - 150ms/epoch - 3ms/step\nEpoch 14/200\n56/56 - 0s - loss: 0.4229 - acc: 0.8249 - 157ms/epoch - 3ms/step\nEpoch 15/200\n56/56 - 0s - loss: 0.4169 - acc: 0.8294 - 149ms/epoch - 3ms/step\nEpoch 16/200\n56/56 - 0s - loss: 0.4203 - acc: 0.8215 - 144ms/epoch - 3ms/step\nEpoch 17/200\n56/56 - 0s - loss: 0.4200 - acc: 0.8316 - 161ms/epoch - 3ms/step\nEpoch 18/200\n56/56 - 0s - loss: 0.4137 - acc: 0.8316 - 142ms/epoch - 3ms/step\nEpoch 19/200\n56/56 - 0s - loss: 0.4186 - acc: 0.8227 - 141ms/epoch - 3ms/step\nEpoch 20/200\n56/56 - 0s - loss: 0.4153 - acc: 0.8294 - 141ms/epoch - 3ms/step\nEpoch 21/200\n56/56 - 0s - loss: 0.4119 - acc: 0.8328 - 146ms/epoch - 3ms/step\nEpoch 22/200\n56/56 - 0s - loss: 0.4103 - acc: 0.8294 - 157ms/epoch - 3ms/step\nEpoch 23/200\n56/56 - 0s - loss: 0.4071 - acc: 0.8294 - 150ms/epoch - 3ms/step\nEpoch 24/200\n56/56 - 0s - loss: 0.4102 - acc: 0.8227 - 153ms/epoch - 3ms/step\nEpoch 25/200\n56/56 - 0s - loss: 0.4045 - acc: 0.8316 - 143ms/epoch - 3ms/step\nEpoch 26/200\n56/56 - 0s - loss: 0.4103 - acc: 0.8272 - 149ms/epoch - 3ms/step\nEpoch 27/200\n56/56 - 0s - loss: 0.4050 - acc: 0.8350 - 153ms/epoch - 3ms/step\nEpoch 28/200\n56/56 - 0s - loss: 0.4063 - acc: 0.8283 - 149ms/epoch - 3ms/step\nEpoch 29/200\n56/56 - 0s - loss: 0.4163 - acc: 0.8260 - 158ms/epoch - 3ms/step\nEpoch 30/200\n56/56 - 0s - loss: 0.4096 - acc: 0.8238 - 161ms/epoch - 3ms/step\nEpoch 31/200\n56/56 - 0s - loss: 0.4064 - acc: 0.8339 - 146ms/epoch - 3ms/step\nEpoch 32/200\n56/56 - 0s - loss: 0.4003 - acc: 0.8350 - 154ms/epoch - 3ms/step\nEpoch 33/200\n56/56 - 0s - loss: 0.4013 - acc: 0.8339 - 144ms/epoch - 3ms/step\nEpoch 34/200\n56/56 - 0s - loss: 0.4048 - acc: 0.8395 - 171ms/epoch - 3ms/step\nEpoch 35/200\n56/56 - 0s - loss: 0.4039 - acc: 0.8305 - 181ms/epoch - 3ms/step\nEpoch 36/200\n56/56 - 0s - loss: 0.3991 - acc: 0.8316 - 155ms/epoch - 3ms/step\nEpoch 37/200\n56/56 - 0s - loss: 0.4034 - acc: 0.8418 - 158ms/epoch - 3ms/step\nEpoch 38/200\n56/56 - 0s - loss: 0.4026 - acc: 0.8361 - 153ms/epoch - 3ms/step\nEpoch 39/200\n56/56 - 0s - loss: 0.3996 - acc: 0.8350 - 157ms/epoch - 3ms/step\nEpoch 40/200\n56/56 - 0s - loss: 0.4013 - acc: 0.8361 - 151ms/epoch - 3ms/step\nEpoch 41/200\n56/56 - 0s - loss: 0.3949 - acc: 0.8418 - 164ms/epoch - 3ms/step\nEpoch 42/200\n56/56 - 0s - loss: 0.3984 - acc: 0.8406 - 152ms/epoch - 3ms/step\nEpoch 43/200\n56/56 - 0s - loss: 0.4073 - acc: 0.8272 - 154ms/epoch - 3ms/step\nEpoch 44/200\n56/56 - 0s - loss: 0.3994 - acc: 0.8305 - 156ms/epoch - 3ms/step\nEpoch 45/200\n56/56 - 0s - loss: 0.3925 - acc: 0.8361 - 153ms/epoch - 3ms/step\nEpoch 46/200\n56/56 - 0s - loss: 0.4060 - acc: 0.8350 - 149ms/epoch - 3ms/step\nEpoch 47/200\n56/56 - 0s - loss: 0.3979 - acc: 0.8350 - 170ms/epoch - 3ms/step\nEpoch 48/200\n56/56 - 0s - loss: 0.4008 - acc: 0.8373 - 191ms/epoch - 3ms/step\nEpoch 49/200\n56/56 - 0s - loss: 0.3943 - acc: 0.8418 - 164ms/epoch - 3ms/step\nEpoch 50/200\n56/56 - 0s - loss: 0.3946 - acc: 0.8418 - 162ms/epoch - 3ms/step\nEpoch 51/200\n56/56 - 0s - loss: 0.3952 - acc: 0.8440 - 154ms/epoch - 3ms/step\nEpoch 52/200\n56/56 - 0s - loss: 0.4015 - acc: 0.8328 - 157ms/epoch - 3ms/step\nEpoch 53/200\n56/56 - 0s - loss: 0.4052 - acc: 0.8350 - 164ms/epoch - 3ms/step\nEpoch 54/200\n56/56 - 0s - loss: 0.3953 - acc: 0.8395 - 154ms/epoch - 3ms/step\nEpoch 55/200\n56/56 - 0s - loss: 0.3933 - acc: 0.8395 - 163ms/epoch - 3ms/step\nEpoch 56/200\n56/56 - 0s - loss: 0.3981 - acc: 0.8418 - 158ms/epoch - 3ms/step\nEpoch 57/200\n56/56 - 0s - loss: 0.3988 - acc: 0.8384 - 146ms/epoch - 3ms/step\nEpoch 58/200\n56/56 - 0s - loss: 0.3986 - acc: 0.8395 - 150ms/epoch - 3ms/step\nEpoch 59/200\n56/56 - 0s - loss: 0.3965 - acc: 0.8339 - 160ms/epoch - 3ms/step\nEpoch 60/200\n56/56 - 0s - loss: 0.3963 - acc: 0.8384 - 152ms/epoch - 3ms/step\nEpoch 61/200\n56/56 - 0s - loss: 0.3956 - acc: 0.8339 - 157ms/epoch - 3ms/step\nEpoch 62/200\n56/56 - 0s - loss: 0.3954 - acc: 0.8384 - 144ms/epoch - 3ms/step\nEpoch 63/200\n56/56 - 0s - loss: 0.3925 - acc: 0.8328 - 147ms/epoch - 3ms/step\nEpoch 64/200\n56/56 - 0s - loss: 0.3918 - acc: 0.8361 - 147ms/epoch - 3ms/step\nEpoch 65/200\n56/56 - 0s - loss: 0.3965 - acc: 0.8316 - 145ms/epoch - 3ms/step\nEpoch 66/200\n56/56 - 0s - loss: 0.3918 - acc: 0.8451 - 154ms/epoch - 3ms/step\nEpoch 67/200\n56/56 - 0s - loss: 0.3924 - acc: 0.8440 - 153ms/epoch - 3ms/step\nEpoch 68/200\n56/56 - 0s - loss: 0.3919 - acc: 0.8384 - 151ms/epoch - 3ms/step\nEpoch 69/200\n56/56 - 0s - loss: 0.3907 - acc: 0.8406 - 153ms/epoch - 3ms/step\nEpoch 70/200\n56/56 - 0s - loss: 0.3926 - acc: 0.8361 - 152ms/epoch - 3ms/step\nEpoch 71/200\n56/56 - 0s - loss: 0.3914 - acc: 0.8328 - 157ms/epoch - 3ms/step\nEpoch 72/200\n56/56 - 0s - loss: 0.3905 - acc: 0.8406 - 158ms/epoch - 3ms/step\nEpoch 73/200\n56/56 - 0s - loss: 0.3876 - acc: 0.8496 - 156ms/epoch - 3ms/step\nEpoch 74/200\n56/56 - 0s - loss: 0.3965 - acc: 0.8361 - 146ms/epoch - 3ms/step\nEpoch 75/200\n56/56 - 0s - loss: 0.3889 - acc: 0.8406 - 157ms/epoch - 3ms/step\nEpoch 76/200\n56/56 - 0s - loss: 0.3880 - acc: 0.8429 - 161ms/epoch - 3ms/step\nEpoch 77/200\n56/56 - 0s - loss: 0.3884 - acc: 0.8406 - 156ms/epoch - 3ms/step\nEpoch 78/200\n56/56 - 0s - loss: 0.3947 - acc: 0.8384 - 150ms/epoch - 3ms/step\nEpoch 79/200\n56/56 - 0s - loss: 0.3891 - acc: 0.8440 - 145ms/epoch - 3ms/step\nEpoch 80/200\n56/56 - 0s - loss: 0.3915 - acc: 0.8384 - 147ms/epoch - 3ms/step\nEpoch 81/200\n56/56 - 0s - loss: 0.3897 - acc: 0.8395 - 145ms/epoch - 3ms/step\nEpoch 82/200\n56/56 - 0s - loss: 0.3931 - acc: 0.8373 - 146ms/epoch - 3ms/step\nEpoch 83/200\n56/56 - 0s - loss: 0.3901 - acc: 0.8328 - 142ms/epoch - 3ms/step\nEpoch 84/200\n56/56 - 0s - loss: 0.3905 - acc: 0.8406 - 140ms/epoch - 3ms/step\nEpoch 85/200\n56/56 - 0s - loss: 0.3868 - acc: 0.8485 - 151ms/epoch - 3ms/step\nEpoch 86/200\n56/56 - 0s - loss: 0.3945 - acc: 0.8485 - 157ms/epoch - 3ms/step\nEpoch 87/200\n56/56 - 0s - loss: 0.3864 - acc: 0.8395 - 147ms/epoch - 3ms/step\nEpoch 88/200\n56/56 - 0s - loss: 0.3897 - acc: 0.8440 - 147ms/epoch - 3ms/step\nEpoch 89/200\n56/56 - 0s - loss: 0.3816 - acc: 0.8395 - 155ms/epoch - 3ms/step\nEpoch 90/200\n56/56 - 0s - loss: 0.3848 - acc: 0.8384 - 155ms/epoch - 3ms/step\nEpoch 91/200\n56/56 - 0s - loss: 0.3827 - acc: 0.8462 - 148ms/epoch - 3ms/step\nEpoch 92/200\n56/56 - 0s - loss: 0.3937 - acc: 0.8373 - 154ms/epoch - 3ms/step\nEpoch 93/200\n56/56 - 0s - loss: 0.3914 - acc: 0.8418 - 150ms/epoch - 3ms/step\nEpoch 94/200\n56/56 - 0s - loss: 0.3915 - acc: 0.8350 - 141ms/epoch - 3ms/step\nEpoch 95/200\n56/56 - 0s - loss: 0.3859 - acc: 0.8406 - 145ms/epoch - 3ms/step\nEpoch 96/200\n56/56 - 0s - loss: 0.3831 - acc: 0.8462 - 149ms/epoch - 3ms/step\nEpoch 97/200\n56/56 - 0s - loss: 0.3859 - acc: 0.8384 - 152ms/epoch - 3ms/step\nEpoch 98/200\n56/56 - 0s - loss: 0.3824 - acc: 0.8462 - 147ms/epoch - 3ms/step\nEpoch 99/200\n56/56 - 0s - loss: 0.3849 - acc: 0.8418 - 152ms/epoch - 3ms/step\nEpoch 100/200\n56/56 - 0s - loss: 0.3846 - acc: 0.8373 - 146ms/epoch - 3ms/step\nEpoch 101/200\n56/56 - 0s - loss: 0.3843 - acc: 0.8373 - 142ms/epoch - 3ms/step\nEpoch 102/200\n56/56 - 0s - loss: 0.3852 - acc: 0.8361 - 139ms/epoch - 2ms/step\nEpoch 103/200\n56/56 - 0s - loss: 0.3819 - acc: 0.8451 - 146ms/epoch - 3ms/step\nEpoch 104/200\n56/56 - 0s - loss: 0.3782 - acc: 0.8496 - 133ms/epoch - 2ms/step\nEpoch 105/200\n56/56 - 0s - loss: 0.3778 - acc: 0.8474 - 145ms/epoch - 3ms/step\nEpoch 106/200\n56/56 - 0s - loss: 0.3856 - acc: 0.8339 - 134ms/epoch - 2ms/step\nEpoch 107/200\n56/56 - 0s - loss: 0.3857 - acc: 0.8339 - 146ms/epoch - 3ms/step\nEpoch 108/200\n56/56 - 0s - loss: 0.3848 - acc: 0.8361 - 149ms/epoch - 3ms/step\nEpoch 109/200\n56/56 - 0s - loss: 0.3860 - acc: 0.8406 - 143ms/epoch - 3ms/step\nEpoch 110/200\n56/56 - 0s - loss: 0.3813 - acc: 0.8395 - 142ms/epoch - 3ms/step\nEpoch 111/200\n56/56 - 0s - loss: 0.3844 - acc: 0.8249 - 153ms/epoch - 3ms/step\nEpoch 112/200\n56/56 - 0s - loss: 0.3857 - acc: 0.8384 - 159ms/epoch - 3ms/step\nEpoch 113/200\n56/56 - 0s - loss: 0.3957 - acc: 0.8429 - 149ms/epoch - 3ms/step\nEpoch 114/200\n56/56 - 0s - loss: 0.3806 - acc: 0.8395 - 140ms/epoch - 3ms/step\nEpoch 115/200\n56/56 - 0s - loss: 0.3835 - acc: 0.8373 - 143ms/epoch - 3ms/step\nEpoch 116/200\n56/56 - 0s - loss: 0.3827 - acc: 0.8373 - 140ms/epoch - 3ms/step\nEpoch 117/200\n56/56 - 0s - loss: 0.3833 - acc: 0.8418 - 137ms/epoch - 2ms/step\nEpoch 118/200\n56/56 - 0s - loss: 0.3741 - acc: 0.8451 - 147ms/epoch - 3ms/step\nEpoch 119/200\n56/56 - 0s - loss: 0.3793 - acc: 0.8462 - 146ms/epoch - 3ms/step\nEpoch 120/200\n56/56 - 0s - loss: 0.3765 - acc: 0.8474 - 176ms/epoch - 3ms/step\nEpoch 121/200\n56/56 - 0s - loss: 0.3744 - acc: 0.8451 - 144ms/epoch - 3ms/step\nEpoch 122/200\n56/56 - 0s - loss: 0.3764 - acc: 0.8440 - 143ms/epoch - 3ms/step\nEpoch 123/200\n56/56 - 0s - loss: 0.3824 - acc: 0.8418 - 139ms/epoch - 2ms/step\nEpoch 124/200\n56/56 - 0s - loss: 0.3828 - acc: 0.8440 - 130ms/epoch - 2ms/step\nEpoch 125/200\n56/56 - 0s - loss: 0.3757 - acc: 0.8418 - 143ms/epoch - 3ms/step\nEpoch 126/200\n56/56 - 0s - loss: 0.3799 - acc: 0.8429 - 142ms/epoch - 3ms/step\nEpoch 127/200\n56/56 - 0s - loss: 0.3776 - acc: 0.8485 - 141ms/epoch - 3ms/step\nEpoch 128/200\n56/56 - 0s - loss: 0.3747 - acc: 0.8429 - 137ms/epoch - 2ms/step\nEpoch 129/200\n56/56 - 0s - loss: 0.3731 - acc: 0.8429 - 146ms/epoch - 3ms/step\nEpoch 130/200\n56/56 - 0s - loss: 0.3745 - acc: 0.8440 - 140ms/epoch - 3ms/step\nEpoch 131/200\n56/56 - 0s - loss: 0.3748 - acc: 0.8474 - 136ms/epoch - 2ms/step\nEpoch 132/200\n56/56 - 0s - loss: 0.3699 - acc: 0.8519 - 141ms/epoch - 3ms/step\nEpoch 133/200\n56/56 - 0s - loss: 0.3743 - acc: 0.8474 - 143ms/epoch - 3ms/step\nEpoch 134/200\n56/56 - 0s - loss: 0.3714 - acc: 0.8451 - 142ms/epoch - 3ms/step\nEpoch 135/200\n56/56 - 0s - loss: 0.3797 - acc: 0.8462 - 141ms/epoch - 3ms/step\nEpoch 136/200\n56/56 - 0s - loss: 0.3798 - acc: 0.8496 - 146ms/epoch - 3ms/step\nEpoch 137/200\n56/56 - 0s - loss: 0.3701 - acc: 0.8451 - 146ms/epoch - 3ms/step\nEpoch 138/200\n56/56 - 0s - loss: 0.3682 - acc: 0.8519 - 134ms/epoch - 2ms/step\nEpoch 139/200\n56/56 - 0s - loss: 0.3825 - acc: 0.8418 - 151ms/epoch - 3ms/step\nEpoch 140/200\n56/56 - 0s - loss: 0.3784 - acc: 0.8440 - 154ms/epoch - 3ms/step\nEpoch 141/200\n56/56 - 0s - loss: 0.3687 - acc: 0.8462 - 150ms/epoch - 3ms/step\nEpoch 142/200\n56/56 - 0s - loss: 0.3707 - acc: 0.8507 - 148ms/epoch - 3ms/step\nEpoch 143/200\n56/56 - 0s - loss: 0.3698 - acc: 0.8418 - 135ms/epoch - 2ms/step\nEpoch 144/200\n56/56 - 0s - loss: 0.3725 - acc: 0.8440 - 136ms/epoch - 2ms/step\nEpoch 145/200\n56/56 - 0s - loss: 0.3641 - acc: 0.8519 - 141ms/epoch - 3ms/step\nEpoch 146/200\n56/56 - 0s - loss: 0.3717 - acc: 0.8418 - 146ms/epoch - 3ms/step\nEpoch 147/200\n56/56 - 0s - loss: 0.3659 - acc: 0.8519 - 133ms/epoch - 2ms/step\nEpoch 148/200\n56/56 - 0s - loss: 0.3728 - acc: 0.8507 - 140ms/epoch - 3ms/step\nEpoch 149/200\n56/56 - 0s - loss: 0.3707 - acc: 0.8462 - 142ms/epoch - 3ms/step\nEpoch 150/200\n56/56 - 0s - loss: 0.3681 - acc: 0.8451 - 142ms/epoch - 3ms/step\nEpoch 151/200\n56/56 - 0s - loss: 0.3638 - acc: 0.8451 - 147ms/epoch - 3ms/step\nEpoch 152/200\n56/56 - 0s - loss: 0.3661 - acc: 0.8507 - 140ms/epoch - 3ms/step\nEpoch 153/200\n56/56 - 0s - loss: 0.3618 - acc: 0.8530 - 149ms/epoch - 3ms/step\nEpoch 154/200\n56/56 - 0s - loss: 0.3697 - acc: 0.8496 - 153ms/epoch - 3ms/step\nEpoch 155/200\n56/56 - 0s - loss: 0.3643 - acc: 0.8485 - 140ms/epoch - 3ms/step\nEpoch 156/200\n56/56 - 0s - loss: 0.3613 - acc: 0.8496 - 134ms/epoch - 2ms/step\nEpoch 157/200\n56/56 - 0s - loss: 0.3693 - acc: 0.8440 - 154ms/epoch - 3ms/step\nEpoch 158/200\n56/56 - 0s - loss: 0.3667 - acc: 0.8485 - 146ms/epoch - 3ms/step\nEpoch 159/200\n56/56 - 0s - loss: 0.3676 - acc: 0.8530 - 140ms/epoch - 3ms/step\nEpoch 160/200\n56/56 - 0s - loss: 0.3706 - acc: 0.8462 - 143ms/epoch - 3ms/step\nEpoch 161/200\n56/56 - 0s - loss: 0.3692 - acc: 0.8440 - 142ms/epoch - 3ms/step\nEpoch 162/200\n56/56 - 0s - loss: 0.3642 - acc: 0.8530 - 149ms/epoch - 3ms/step\nEpoch 163/200\n56/56 - 0s - loss: 0.3597 - acc: 0.8530 - 154ms/epoch - 3ms/step\nEpoch 164/200\n56/56 - 0s - loss: 0.3641 - acc: 0.8530 - 147ms/epoch - 3ms/step\nEpoch 165/200\n56/56 - 0s - loss: 0.3582 - acc: 0.8530 - 142ms/epoch - 3ms/step\nEpoch 166/200\n56/56 - 0s - loss: 0.3626 - acc: 0.8530 - 164ms/epoch - 3ms/step\nEpoch 167/200\n56/56 - 0s - loss: 0.3635 - acc: 0.8462 - 154ms/epoch - 3ms/step\nEpoch 168/200\n56/56 - 0s - loss: 0.3754 - acc: 0.8406 - 161ms/epoch - 3ms/step\nEpoch 169/200\n56/56 - 0s - loss: 0.3653 - acc: 0.8519 - 173ms/epoch - 3ms/step\nEpoch 170/200\n56/56 - 0s - loss: 0.3569 - acc: 0.8541 - 164ms/epoch - 3ms/step\nEpoch 171/200\n56/56 - 0s - loss: 0.3582 - acc: 0.8519 - 161ms/epoch - 3ms/step\nEpoch 172/200\n56/56 - 0s - loss: 0.3678 - acc: 0.8384 - 169ms/epoch - 3ms/step\nEpoch 173/200\n56/56 - 0s - loss: 0.3744 - acc: 0.8451 - 154ms/epoch - 3ms/step\nEpoch 174/200\n56/56 - 0s - loss: 0.3656 - acc: 0.8496 - 139ms/epoch - 2ms/step\nEpoch 175/200\n56/56 - 0s - loss: 0.3704 - acc: 0.8418 - 142ms/epoch - 3ms/step\nEpoch 176/200\n56/56 - 0s - loss: 0.3592 - acc: 0.8541 - 147ms/epoch - 3ms/step\nEpoch 177/200\n56/56 - 0s - loss: 0.3719 - acc: 0.8530 - 141ms/epoch - 3ms/step\nEpoch 178/200\n56/56 - 0s - loss: 0.3724 - acc: 0.8507 - 146ms/epoch - 3ms/step\nEpoch 179/200\n56/56 - 0s - loss: 0.3734 - acc: 0.8429 - 158ms/epoch - 3ms/step\nEpoch 180/200\n56/56 - 0s - loss: 0.3652 - acc: 0.8485 - 148ms/epoch - 3ms/step\nEpoch 181/200\n56/56 - 0s - loss: 0.3586 - acc: 0.8530 - 141ms/epoch - 3ms/step\nEpoch 182/200\n56/56 - 0s - loss: 0.3594 - acc: 0.8563 - 142ms/epoch - 3ms/step\nEpoch 183/200\n56/56 - 0s - loss: 0.3506 - acc: 0.8575 - 148ms/epoch - 3ms/step\nEpoch 184/200\n56/56 - 0s - loss: 0.3600 - acc: 0.8586 - 156ms/epoch - 3ms/step\nEpoch 185/200\n56/56 - 0s - loss: 0.3569 - acc: 0.8552 - 138ms/epoch - 2ms/step\nEpoch 186/200\n56/56 - 0s - loss: 0.3517 - acc: 0.8586 - 148ms/epoch - 3ms/step\nEpoch 187/200\n56/56 - 0s - loss: 0.3510 - acc: 0.8620 - 146ms/epoch - 3ms/step\nEpoch 188/200\n56/56 - 0s - loss: 0.3544 - acc: 0.8530 - 140ms/epoch - 2ms/step\nEpoch 189/200\n56/56 - 0s - loss: 0.3559 - acc: 0.8552 - 147ms/epoch - 3ms/step\nEpoch 190/200\n56/56 - 0s - loss: 0.3536 - acc: 0.8485 - 151ms/epoch - 3ms/step\nEpoch 191/200\n56/56 - 0s - loss: 0.3525 - acc: 0.8530 - 135ms/epoch - 2ms/step\nEpoch 192/200\n56/56 - 0s - loss: 0.3472 - acc: 0.8563 - 153ms/epoch - 3ms/step\nEpoch 193/200\n56/56 - 0s - loss: 0.3494 - acc: 0.8620 - 181ms/epoch - 3ms/step\nEpoch 194/200\n56/56 - 0s - loss: 0.3579 - acc: 0.8507 - 140ms/epoch - 3ms/step\nEpoch 195/200\n56/56 - 0s - loss: 0.3685 - acc: 0.8496 - 147ms/epoch - 3ms/step\nEpoch 196/200\n56/56 - 0s - loss: 0.3555 - acc: 0.8496 - 136ms/epoch - 2ms/step\nEpoch 197/200\n56/56 - 0s - loss: 0.3857 - acc: 0.8451 - 137ms/epoch - 2ms/step\nEpoch 198/200\n56/56 - 0s - loss: 0.3778 - acc: 0.8440 - 139ms/epoch - 2ms/step\nEpoch 199/200\n56/56 - 0s - loss: 0.3565 - acc: 0.8563 - 145ms/epoch - 3ms/step\nEpoch 200/200\n56/56 - 0s - loss: 0.3531 - acc: 0.8552 - 144ms/epoch - 3ms/step\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f219406f160>"},"metadata":{}}]}]}